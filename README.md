# CryptoSlon - фреймворк агентов для хакатона
CryptoSlon — это минималистичный фреймворк для быстрого прототипирования AI-агентов под задачи хакатона:  
от подключения LLM и векторных БД до полного RAG-пайплайна. Он упрощает интеграцию GigaChat, OpenAI, Google Gemini и Groq, 
поддерживает многоязычный поиск, и даёт готовые классы для добавления своих агентов.

Текущий прогресс: 
- подключение LLM - done
- Векторные БД - done
- Векторизация текстов - done
- RAG - done
- Агенты - in progress
- next steps - TBD
## Установка и настройка

### 1. Установка зависимостей
```bash
pip install -r requirements.txt
```

### 2. Настройка переменных окружения
Скопируйте `.env.example` в `.env` и добавьте API ключи:
```bash
cp .env.example .env
```

Заполните файл `.env`:
```
GIGACHAT_CREDENTIALS=ваш_ключ_gigachat - необходимо
OPENAI_API_KEY=ваш_ключ_openai - опционально
GOOGLE_API_KEY=ваш_ключ_google - опционально
GROQ_API_KEY=ваш_ключ_groq - опционально
SERPER_API_KEY=ваш_ключ_serper - необходимо (гугл-поиск)
```

## Использование

### 1. Работа с LLM

#### Базовое использование
```python
from LLMs.factory import get_llm_client

# Создание клиента
llm = get_llm_client("gigachat")  # или "openai", "google", "groq"

# Простой запрос
response = llm.chat_one("Привет, как дела?")
print(response)

# Запрос с системным промптом
system_prompt = "Ты эксперт по кибербезопасности"
response = llm.chat_one("Что такое SQL injection?", system_prompt)
print(response)
```
Пример вызова смотри в **ДОБАВИТЬ ФАЙЛ**


### 2. Создание векторной базы данных
Векторная БД — это хранилище, которое сохраняет тексты, изображения или другие данные в виде числовых векторов (эмбеддингов).
Эти векторы позволяют сравнивать смысловую близость объектов, а не только точное совпадение слов.
Зачем нужна:
- Позволяет находить документы, схожие по смыслу, даже если запрос и текст формулированы по-разному.
- Используется в RAG-системах, чат-ботах и рекомендательных сервисах для быстрого поиска релевантной информации.
- Хорошо работает с многоязычными моделями, что даёт возможность искать по текстам на разных языках.

Сохраняет данные на локальную машину. Экземпляр БД должен быть построен на основе класса BaseChromaDB, 
который наследуется от BaseVectorDB

Пример:
```python
from VectorDB.base_chroma_db import BaseChromaDB

# Создание базы данных
vector_db = BaseChromaDB(
    collection_name="cybersec_knowledge",
    model_name="intfloat/multilingual-e5-base"  # Поддерживает русский язык
)
```

### 3. Векторизация .txt файлов
_Для запуска векторизации необходима существующая векторная БД_

#### Метод 1: Добавление файлов
Используется для добавления новой информации, а так же для первой записи в БД
```python
from vectorize_documents import SimpleVectorizer

# Инициализация
vectorizer = SimpleVectorizer("my_knowledge_base")

# Список файлов для обработки
files = [
    "data/security_doc1.txt",
    "data/malware_analysis.txt"
]

# Векторизация
metrics = vectorizer.vectorize_files(files)
vectorizer.print_report(metrics)
```
В metrics сохраняется результат записи данных в из files в базу "my_knowledge_base". 
Выводить результат записи необязательно.
#### Метод 2: Чистое обновление (удаляет старые данные)
Используется, когда требуется обновить базу данных и исключить дупликацию данных, например, в случае, 
когда существующий файл был дополнен новой информацией.
```python
# Полная перезапись базы данных
metrics = vectorizer.clean_and_add(files)
vectorizer.print_report(metrics)
```
Запустить векторизацию можно из файла vectorize_documents.py

### 4. Использование RAG системы

#### Тестирование RAG системы
```bash
python test_full_rag.py
```

## Структура проекта

```
CryptoSlon/
├── LLMs/                  # LLM клиенты
│   ├── BaseLLMClient.py   # Базовый класс
│   ├── GigaChatClient.py  # GigaChat
│   ├── OpenAIClient.py    # OpenAI
│   └── factory.py         # Фабрика клиентов
├── VectorDB/              # Векторная база данных
│   ├── base_vector_db.py  # Интерфейс
│   ├── base_chroma_db.py  # ChromaDB реализация
│   └── document_ingestion.py  # Обработка документов
├── rag/                   # RAG компоненты
│   ├── queryprep.py       # Обработка запросов
│   └── pipeline.py        # Основной пайплайн
├── prompts/               # Шаблоны промптов
│   └── templates/         # JSON шаблоны
├── data/                  # Данные для обработки
├── chroma_db/             # База данных ChromaDB
└── requirements.txt       # Зависимости
```

## Поддерживаемые модели

- **GigaChat** - российская LLM с поддержкой русского языка
- **Google Gemini** - модели Gemini
- **Groq** - быстрые модели

_Легко расширяется созданием обертки вокруг BaseLLMClient_

## Советы по использованию

1. **Начните с малого**: Добавьте несколько небольших документов для тестирования
2. **Используйте подходящую модель**: `multilingual-e5-base` хорошо работает с русским текстом
3. **Настройте chunk_size**: Для технических документов рекомендуется 800-1200 символов
4. **Проверяйте distance**: Значения < 0.8 обычно означают релевантные результаты

## Устранение неполадок

### Проблемы с кодировкой
Убедитесь, что файлы сохранены в UTF-8 кодировке.

### Ошибки API ключей
Проверьте правильность заполнения файла `.env`.

### Медленная работа
Для ускорения используйте меньший размер chunks или модель меньшего размера.

## Логирование

Уровень логирования можно настроить в файлах:
```python
logging.basicConfig(level=logging.WARNING)  # Только предупреждения и ошибки
logging.basicConfig(level=logging.INFO)     # Подробная информация
```