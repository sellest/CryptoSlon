#!/usr/bin/env python3
"""
Vulnerability Fixer - Processes vulnerability snippets and calls LLM to generate fixes
using the vulnerability_fix template.
"""

import json
import sys
from pathlib import Path
from typing import Dict, List, Any

# Add parent directory to path to import LLMs and prompts
sys.path.append(str(Path(__file__).parent.parent))

from LLMs.factory import get_llm_client
from prompts.PromptManager import PromptManager

# Import from parent directory
parent_dir = str(Path(__file__).parent.parent)
if parent_dir not in sys.path:
    sys.path.append(parent_dir)
from progress_indicator import ProgressIndicator


class VulnerabilityFixer:
    def __init__(self, 
                 snippet_report_path: str,
                 model: str = "gpt-4o-mini",
                 template_name: str = "vulnerability_fix"):
        """
        Initialize Vulnerability Fixer
        
        Args:
            snippet_report_path: Path to vulnerability snippets JSON
            model: LLM model to use for generating fixes
            template_name: Prompt template name (without .json extension)
        """
        self.snippet_report_path = snippet_report_path
        self.model = model
        self.template_name = template_name
        self.progress_indicator = ProgressIndicator()
        
        # Load snippet report
        self.snippet_data = self._load_json(snippet_report_path)
        self.vulnerabilities = self.snippet_data.get("vulnerabilities", [])
        
        # Initialize LLM client
        try:
            self.llm_client = get_llm_client(model)
            print(f"‚úÖ Initialized LLM client: {model}")
        except Exception as e:
            print(f"‚ùå Failed to initialize LLM client: {e}")
            raise
        
        # Initialize prompt manager
        try:
            self.prompt_manager = PromptManager()
            print(f"‚úÖ Initialized prompt manager")
        except Exception as e:
            print(f"‚ùå Failed to initialize prompt manager: {e}")
            raise
    
    def _load_json(self, file_path: str) -> Dict[str, Any]:
        """Load JSON file."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"‚úÖ Loaded: {file_path}")
            return data
        except FileNotFoundError:
            print(f"‚ùå File not found: {file_path}")
            raise
        except json.JSONDecodeError as e:
            print(f"‚ùå Invalid JSON in {file_path}: {e}")
            raise
    
    def _prepare_messages(self, vulnerability: Dict[str, Any]) -> List[Dict[str, str]]:
        """Prepare messages for LLM using vulnerability fix template."""
        try:
            # Load template data
            template_data = self.prompt_manager.load_template(self.template_name)
            
            # Prepare template variables
            location_data = vulnerability.get("location", {})
            vulnerable_lines = location_data.get("vulnerable_lines_only", "No code available")
            context_data = vulnerability.get("context", {})
            
            template_vars = {
                "vulnerability_type": vulnerability.get("vulnerability", "Unknown vulnerability"),
                "cwe_id": vulnerability.get("cwe", "Unknown CWE"),
                "severity": vulnerability.get("severity", "UNKNOWN"),
                "suggested_fix": vulnerability.get("suggested_fix", "No specific fix provided"),
                "vulnerable_lines": vulnerable_lines,
                "context_before": context_data.get("before", "No context available"),
                "context_after": context_data.get("after", "No context available"),
                "start_line": location_data.get("start_line", 0),
                "end_line": location_data.get("end_line", 0)
            }
            
            messages = []
            
            # Process each message in template
            for message in template_data.get("messages", []):
                role = message.get("role", "user")
                content = message.get("content", "")
                
                # Substitute variables in content
                for var_name, var_value in template_vars.items():
                    placeholder = f"{{{{{var_name}}}}}"
                    content = content.replace(placeholder, str(var_value))
                
                messages.append({
                    "role": role,
                    "content": content
                })
            
            return messages
            
        except Exception as e:
            print(f"‚ùå Failed to prepare messages: {e}")
            raise
    
    def fix_vulnerability(self, vulnerability: Dict[str, Any]) -> Dict[str, Any]:
        """Generate fix for a single vulnerability using LLM."""
        try:
            # Prepare messages
            messages = self._prepare_messages(vulnerability)
            
            # Start progress indicator
            vuln_name = vulnerability.get("vulnerability", "Unknown")[:30]
            self.progress_indicator.start(f"Generating fix for {vuln_name}")
            
            # Call LLM
            response = self.llm_client.chat_raw(messages)
            
            # Stop progress indicator
            self.progress_indicator.stop()
            
            # Handle location format - convert to {start_line, end_line} format
            location_data = vulnerability.get("location", {})
            location_output = {
                "start_line": location_data.get("start_line", 0),
                "end_line": location_data.get("end_line", 0)
            }
            original_code = location_data.get("vulnerable_lines_only", "")
            
            # Create result object
            result = {
                "vulnerability_info": {
                    "type": vulnerability.get("vulnerability", ""),
                    "cwe": vulnerability.get("cwe", ""),
                    "file": vulnerability.get("file", ""),
                    "location": location_output,
                    "severity": vulnerability.get("severity", "")
                },
                "original_code": original_code,
                "suggested_fix": vulnerability.get("suggested_fix", ""),
                "llm_response": response,
                "model_used": self.model
            }
            
            return result
            
        except Exception as e:
            # Make sure to stop progress indicator on error
            self.progress_indicator.stop()
            print(f"‚ùå Failed to fix vulnerability: {e}")
            
            # Handle location format for error case too
            location_data = vulnerability.get("location", {})
            location_output = {
                "start_line": location_data.get("start_line", 0),
                "end_line": location_data.get("end_line", 0)
            }
            original_code = location_data.get("vulnerable_lines_only", "")
            
            return {
                "vulnerability_info": {
                    "type": vulnerability.get("vulnerability", ""),
                    "cwe": vulnerability.get("cwe", ""),
                    "file": vulnerability.get("file", ""),
                    "location": location_output
                },
                "original_code": original_code,
                "suggested_fix": vulnerability.get("suggested_fix", ""),
                "llm_response": "",
                "error": str(e),
                "model_used": self.model
            }
    
    def fix_all_vulnerabilities(self, 
                               max_vulnerabilities: int = None,
                               show_progress: bool = True) -> List[Dict[str, Any]]:
        """
        Fix all vulnerabilities using LLM.
        
        Args:
            max_vulnerabilities: Limit number of vulnerabilities to process (for testing)
            show_progress: Show progress during processing
            
        Returns:
            List of vulnerability fix results
        """
        vulnerabilities_to_process = self.vulnerabilities
        if max_vulnerabilities:
            vulnerabilities_to_process = self.vulnerabilities[:max_vulnerabilities]
        
        print(f"üîß Fixing {len(vulnerabilities_to_process)} vulnerabilities using {self.model}...")
        
        fixed_results = []
        
        for i, vuln in enumerate(vulnerabilities_to_process, 1):
            if show_progress:
                print(f"\n[{i}/{len(vulnerabilities_to_process)}] Fixing: {vuln.get('vulnerability', 'Unknown')[:50]}...")
                print(f"  File: {vuln.get('file', 'Unknown')} (lines {vuln.get('location', 'Unknown')})")
            
            # Fix vulnerability
            result = self.fix_vulnerability(vuln)
            fixed_results.append(result)
            
            if show_progress and result.get("llm_response"):
                print(f"  ‚úÖ Generated fix ({len(result['llm_response'])} characters)")
            elif show_progress:
                print(f"  ‚ö†Ô∏è  No fix generated")
        
        print(f"\n‚úÖ Completed fixing {len(fixed_results)} vulnerabilities")
        return fixed_results
    
    def save_fixes_report(self, fixes: List[Dict[str, Any]], output_file: str):
        """Save vulnerability fixes to JSON file."""
        report = {
            "metadata": {
                "source_report": self.snippet_report_path,
                "model": self.model,
                "template": self.template_name,
                "generated_at": "2025-08-24T00:00:00Z",
                "total_fixes": len(fixes)
            },
            "fixes": fixes
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Fixes report saved to: {output_file}")
    
    def generate_summary(self, fixes: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate summary statistics for fixes."""
        total_fixes = len(fixes)
        successful_fixes = sum(1 for fix in fixes if fix.get("llm_response"))
        failed_fixes = total_fixes - successful_fixes
        
        # Count by severity
        severity_counts = {}
        for fix in fixes:
            severity = fix.get("vulnerability_info", {}).get("severity", "UNKNOWN")
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        # Count by CWE
        cwe_counts = {}
        for fix in fixes:
            cwe = fix.get("vulnerability_info", {}).get("cwe", "UNKNOWN")
            cwe_counts[cwe] = cwe_counts.get(cwe, 0) + 1
        
        return {
            "total_vulnerabilities": total_fixes,
            "successful_fixes": successful_fixes,
            "failed_fixes": failed_fixes,
            "success_rate": (successful_fixes / total_fixes * 100) if total_fixes > 0 else 0,
            "severity_distribution": severity_counts,
            "cwe_distribution": dict(sorted(cwe_counts.items(), key=lambda x: x[1], reverse=True)[:10])
        }


def fix_vulnerabilities(
    snippet_report: str,
    output_file: str = "vulnerability_fixes.json",
    model: str = "gpt-4o-mini",
    template: str = "vulnerability_fix",
    max_vulnerabilities: int = None,
    show_summary: bool = True
) -> List[Dict[str, Any]]:
    """
    Fix vulnerabilities using LLM.
    
    Args:
        snippet_report: Path to vulnerability snippets JSON
        output_file: Output file for fixes
        model: LLM model to use
        template: Prompt template name
        max_vulnerabilities: Limit number to process (for testing)
        show_summary: Show summary after completion
        
    Returns:
        List of vulnerability fix results
    """
    fixer = VulnerabilityFixer(snippet_report, model, template)
    fixes = fixer.fix_all_vulnerabilities(max_vulnerabilities, show_progress=True)
    
    # Save fixes report
    fixer.save_fixes_report(fixes, output_file)
    
    # Show summary if requested
    if show_summary:
        summary = fixer.generate_summary(fixes)
        print(f"\nüìä Fixing Summary:")
        print(f"  Total vulnerabilities: {summary['total_vulnerabilities']}")
        print(f"  Successful fixes: {summary['successful_fixes']}")
        print(f"  Failed fixes: {summary['failed_fixes']}")
        print(f"  Success rate: {summary['success_rate']:.1f}%")
        print(f"  Severity distribution: {summary['severity_distribution']}")
    
    return fixes


def main():
    """Example usage with Python parameters."""
    try:
        # Fix vulnerabilities from snippet report
        dir_path = "/Users/izelikson/python/CryptoSlon/SAST/reports/test_5"
        fixes = fix_vulnerabilities(
            snippet_report=f"{dir_path}/vulnerability_snippets.json",
            output_file=f"{dir_path}/vulnerability_fixes.json",
            model="gpt-5",
            template="vulnerability_fix_v5",
            max_vulnerabilities=5,
            show_summary=True
        )
        
        print(f"\n‚úÖ Vulnerability fixing completed successfully!")
        print(f"üîß Generated {len(fixes)} vulnerability fixes")
        
        # Example: Show sample fixes
        successful_fixes = [f for f in fixes if f.get("llm_response")]
        if successful_fixes:
            print(f"\nüìã Sample successful fixes:")
            for fix in successful_fixes[:2]:
                vuln_info = fix.get("vulnerability_info", {})
                print(f"\nüî∏ {vuln_info.get('type', 'Unknown')}")
                print(f"  File: {vuln_info.get('file', 'Unknown')} (lines {vuln_info.get('location', 'Unknown')})")
                print(f"  CWE: {vuln_info.get('cwe', 'Unknown')}")
                print(f"  Fixed code preview: {fix.get('llm_response', '')[:100]}...")
        
        return fixes
        
    except Exception as e:
        print(f"\n‚ùå Vulnerability fixing failed: {e}")
        import traceback
        traceback.print_exc()
        return []


if __name__ == "__main__":
    # Direct Python usage
    result = main()
