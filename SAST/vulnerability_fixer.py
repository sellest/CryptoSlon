#!/usr/bin/env python3
"""
Vulnerability Fixer - Processes vulnerability snippets and calls LLM to generate fixes
using the vulnerability_fix template.
"""

import json
import logging
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional

# Setup logging
logger = logging.getLogger(__name__)

# Add parent directory to path to import LLMs and prompts
sys.path.append(str(Path(__file__).parent.parent))

from LLMs.factory import get_llm_client
from prompts.PromptManager import PromptManager

# Import from parent directory
parent_dir = str(Path(__file__).parent.parent)
if parent_dir not in sys.path:
    sys.path.append(parent_dir)
from progress_indicator import ProgressIndicator


class VulnerabilityFixer:
    """
    Processes vulnerability snippets and generates fixes using LLM with prompt templates.
    
    This class takes vulnerability snippets (from SnippetExtractor) and calls an LLM 
    to generate fixes for each vulnerability using configurable prompt templates.
    It supports various LLM providers through the factory pattern.
    
    Attributes:
        snippet_report_path (str): Path to the vulnerability snippets JSON file
        model (str): LLM model identifier for fix generation
        template_name (str): Name of the prompt template to use
        llm_client: Initialized LLM client instance
        prompt_manager: Prompt template manager instance
        snippet_data (Dict[str, Any]): Loaded snippet report data
        vulnerabilities (List[Dict[str, Any]]): List of vulnerability objects
        progress_indicator: Progress indicator for user feedback
        
    Example:
        fixer = VulnerabilityFixer("snippets.json", "gpt-4o", "vulnerability_fix")
        fixes = fixer.fix_all_vulnerabilities(max_vulnerabilities=10)
        fixer.save_fixes_report(fixes, "fixes.json")
    """
    
    def __init__(self, 
                 snippet_report_path: str,
                 model: str = "gpt-4o-mini",
                 template_name: str = "vulnerability_fix") -> None:
        """
        Initialize Vulnerability Fixer
        
        Args:
            snippet_report_path: Path to vulnerability snippets JSON
            model: LLM model to use for generating fixes
            template_name: Prompt template name (without .json extension)
        """
        self.snippet_report_path = snippet_report_path
        self.model = model
        self.template_name = template_name
        self.progress_indicator = ProgressIndicator()
        
        # Load snippet report
        self.snippet_data = self._load_json(snippet_report_path)
        self.vulnerabilities = self.snippet_data.get("vulnerabilities", [])
        
        # Initialize LLM client
        try:
            self.llm_client = get_llm_client(model)
            logger.info(f"Initialized LLM client: {model}")
        except Exception as e:
            logger.error(f"Failed to initialize LLM client: {e}")
            raise
        
        # Initialize prompt manager
        try:
            self.prompt_manager = PromptManager()
            logger.info(f"Initialized prompt manager")
        except Exception as e:
            logger.error(f"Failed to initialize prompt manager: {e}")
            raise
    
    def _load_json(self, file_path: str) -> Dict[str, Any]:
        """Load JSON file."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            logger.info(f"Loaded: {file_path}")
            return data
        except FileNotFoundError:
            logger.error(f"File not found: {file_path}")
            raise
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in {file_path}: {e}")
            raise
    
    def _prepare_messages(self, vulnerability: Dict[str, Any]) -> List[Dict[str, str]]:
        """Prepare messages for LLM using vulnerability fix template."""
        try:
            # Load template data
            template_data = self.prompt_manager.load_template(self.template_name)
            
            # Prepare template variables
            location_data = vulnerability.get("location", {})
            vulnerable_lines = location_data.get("vulnerable_lines_only", "No code available")
            context_data = vulnerability.get("context", {})
            
            template_vars = {
                "vulnerability_type": vulnerability.get("vulnerability", "Unknown vulnerability"),
                "cwe_id": vulnerability.get("cwe", "Unknown CWE"),
                "severity": vulnerability.get("severity", "UNKNOWN"),
                # "suggested_fix": vulnerability.get("suggested_fix", "No specific fix provided"),
                "vulnerable_lines": vulnerable_lines,
                "context_before": context_data.get("before", "No context available"),
                "context_after": context_data.get("after", "No context available"),
                "start_line": location_data.get("start_line", 0),
                "end_line": location_data.get("end_line", 0)
            }
            
            messages = []
            
            # Process each message in template
            for message in template_data.get("messages", []):
                role = message.get("role", "user")
                content = message.get("content", "")
                
                # Substitute variables in content
                for var_name, var_value in template_vars.items():
                    placeholder = f"{{{{{var_name}}}}}"
                    content = content.replace(placeholder, str(var_value))
                
                messages.append({
                    "role": role,
                    "content": content
                })
            
            return messages
            
        except Exception as e:
            logger.error(f"Failed to prepare messages: {e}")
            raise
    
    def fix_vulnerability(self, vulnerability: Dict[str, Any]) -> Dict[str, Any]:
        """Generate fix for a single vulnerability using LLM."""
        try:
            # Prepare messages
            messages = self._prepare_messages(vulnerability)
            
            # Start progress indicator
            vuln_name = vulnerability.get("vulnerability", "Unknown")[:30]
            self.progress_indicator.start(f"Generating fix for {vuln_name}")
            
            # Call LLM
            response = self.llm_client.chat_raw(messages)
            
            # Stop progress indicator
            self.progress_indicator.stop()
            
            # Handle location format - convert to {start_line, end_line} format
            location_data = vulnerability.get("location", {})
            location_output = {
                "start_line": location_data.get("start_line", 0),
                "end_line": location_data.get("end_line", 0)
            }
            original_code = location_data.get("vulnerable_lines_only", "")
            
            # Create result object
            result = {
                "vulnerability_info": {
                    "type": vulnerability.get("vulnerability", ""),
                    "cwe": vulnerability.get("cwe", ""),
                    "file": vulnerability.get("file", ""),
                    "location": location_output,
                    "severity": vulnerability.get("severity", "")
                },
                "original_code": original_code,
                # "suggested_fix": vulnerability.get("suggested_fix", ""),
                "llm_response": response,
                "model_used": self.model
            }
            
            return result
            
        except Exception as e:
            # Make sure to stop progress indicator on error
            self.progress_indicator.stop()
            logger.error(f"Failed to fix vulnerability: {e}")
            
            # Handle location format for error case too
            location_data = vulnerability.get("location", {})
            location_output = {
                "start_line": location_data.get("start_line", 0),
                "end_line": location_data.get("end_line", 0)
            }
            original_code = location_data.get("vulnerable_lines_only", "")
            
            return {
                "vulnerability_info": {
                    "type": vulnerability.get("vulnerability", ""),
                    "cwe": vulnerability.get("cwe", ""),
                    "file": vulnerability.get("file", ""),
                    "location": location_output
                },
                "original_code": original_code,
                # "suggested_fix": vulnerability.get("suggested_fix", ""),
                "llm_response": "",
                "error": str(e),
                "model_used": self.model
            }
    
    def fix_all_vulnerabilities(self, 
                               max_vulnerabilities: Optional[int] = None,
                               show_progress: bool = True) -> List[Dict[str, Any]]:
        """
        Fix all vulnerabilities using LLM.
        
        Args:
            max_vulnerabilities: Limit number of vulnerabilities to process (for testing)
            show_progress: Show progress during processing
            
        Returns:
            List of vulnerability fix results
        """
        vulnerabilities_to_process = self.vulnerabilities
        if max_vulnerabilities:
            vulnerabilities_to_process = self.vulnerabilities[:max_vulnerabilities]
        
        logger.info(f"Fixing {len(vulnerabilities_to_process)} vulnerabilities using {self.model}")
        
        fixed_results = []
        
        for i, vuln in enumerate(vulnerabilities_to_process, 1):
            if show_progress:
                logger.info(f"[{i}/{len(vulnerabilities_to_process)}] Fixing: {vuln.get('vulnerability', 'Unknown')[:50]}")
                logger.debug(f"  File: {vuln.get('file', 'Unknown')} (lines {vuln.get('location', 'Unknown')})")
            
            # Fix vulnerability
            result = self.fix_vulnerability(vuln)
            fixed_results.append(result)
            
            if show_progress and result.get("llm_response"):
                logger.debug(f"  Generated fix ({len(result['llm_response'])} characters)")
            elif show_progress:
                logger.warning(f"  No fix generated")
        
        logger.info(f"Completed fixing {len(fixed_results)} vulnerabilities")
        return fixed_results
    
    def save_fixes_report(self, fixes: List[Dict[str, Any]], output_file: str) -> None:
        """Save vulnerability fixes to JSON file."""
        report = {
            "metadata": {
                "source_report": self.snippet_report_path,
                "model": self.model,
                "template": self.template_name,
                "generated_at": "2025-08-24T00:00:00Z",
                "total_fixes": len(fixes)
            },
            "fixes": fixes
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Fixes report saved to: {output_file}")
    
    def generate_summary(self, fixes: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate summary statistics for fixes."""
        total_fixes = len(fixes)
        successful_fixes = sum(1 for fix in fixes if fix.get("llm_response"))
        failed_fixes = total_fixes - successful_fixes
        
        # Count by severity
        severity_counts = {}
        for fix in fixes:
            severity = fix.get("vulnerability_info", {}).get("severity", "UNKNOWN")
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        # Count by CWE
        cwe_counts = {}
        for fix in fixes:
            cwe = fix.get("vulnerability_info", {}).get("cwe", "UNKNOWN")
            cwe_counts[cwe] = cwe_counts.get(cwe, 0) + 1
        
        return {
            "total_vulnerabilities": total_fixes,
            "successful_fixes": successful_fixes,
            "failed_fixes": failed_fixes,
            "success_rate": (successful_fixes / total_fixes * 100) if total_fixes > 0 else 0,
            "severity_distribution": severity_counts,
            "cwe_distribution": dict(sorted(cwe_counts.items(), key=lambda x: x[1], reverse=True)[:10])
        }


def run_vulnerability_fixer(**kwargs) -> Dict[str, Any]:
    """
    Agent-friendly helper function for fixing vulnerabilities using LLM.
    
    Args:
        snippet_report (str): Path to vulnerability snippets JSON file (required)
        output_file (str, optional): Output file path for fixes (default: 'vulnerability_fixes.json')
        model (str, optional): LLM model to use (default: 'gpt-4o-mini')
        template (str, optional): Prompt template name (default: 'vulnerability_fix')
        max_vulnerabilities (int, optional): Limit number to process for testing
        show_summary (bool, optional): Whether to display fixing summary (default: False)
        show_progress (bool, optional): Show progress during processing (default: False)
        log_level (str, optional): Logging level ('DEBUG', 'INFO', 'WARNING', 'ERROR')
        
    Returns:
        Dict with standardized format:
        {
            "success": bool,
            "data": {
                "fixes": list of fix objects or None,
                "total_fixes": int,
                "successful_fixes": int,
                "failed_fixes": int,
                "success_rate": float,
                "output_file": str,
                "model_used": str,
                "template_used": str,
                "severity_distribution": dict,
                "cwe_distribution": dict
            },
            "error": str or None,
            "metadata": {
                "snippet_report": str,
                "max_vulnerabilities": int or None,
                "show_summary": bool,
                "show_progress": bool
            }
        }
    """
    # Set logging level if provided
    if 'log_level' in kwargs:
        logger.setLevel(getattr(logging, kwargs['log_level'].upper(), logging.INFO))
    
    # Validate required parameters
    if 'snippet_report' not in kwargs:
        return {
            "success": False,
            "data": None,
            "error": "snippet_report is required",
            "metadata": {}
        }
    
    # Extract parameters with defaults
    snippet_report = kwargs['snippet_report']
    output_file = kwargs.get('output_file', 'vulnerability_fixes.json')
    model = kwargs.get('model', 'gpt-4o-mini')
    template = kwargs.get('template', 'vulnerability_fix')
    max_vulnerabilities = kwargs.get('max_vulnerabilities')
    show_summary = kwargs.get('show_summary', False)
    show_progress = kwargs.get('show_progress', False)
    
    try:
        # Initialize fixer
        fixer = VulnerabilityFixer(snippet_report, model, template)
        
        # Fix vulnerabilities
        fixes = fixer.fix_all_vulnerabilities(max_vulnerabilities, show_progress)
        
        # Save fixes report
        fixer.save_fixes_report(fixes, output_file)
        
        # Generate summary
        summary = fixer.generate_summary(fixes)
        
        # Display summary if requested
        if show_summary:
            logger.info(f"Fixing Summary:")
            logger.info(f"  Total vulnerabilities: {summary['total_vulnerabilities']}")
            logger.info(f"  Successful fixes: {summary['successful_fixes']}")
            logger.info(f"  Failed fixes: {summary['failed_fixes']}")
            logger.info(f"  Success rate: {summary['success_rate']:.1f}%")
            logger.info(f"  Severity distribution: {summary['severity_distribution']}")
        
        return {
            "success": True,
            "data": {
                "fixes": fixes,
                "total_fixes": summary['total_vulnerabilities'],
                "successful_fixes": summary['successful_fixes'],
                "failed_fixes": summary['failed_fixes'],
                "success_rate": summary['success_rate'],
                "output_file": output_file,
                "model_used": model,
                "template_used": template,
                "severity_distribution": summary['severity_distribution'],
                "cwe_distribution": summary['cwe_distribution']
            },
            "error": None,
            "metadata": {
                "snippet_report": str(snippet_report),
                "max_vulnerabilities": max_vulnerabilities,
                "show_summary": show_summary,
                "show_progress": show_progress
            }
        }
        
    except Exception as e:
        logger.exception("Exception occurred during vulnerability fixing")
        return {
            "success": False,
            "data": None,
            "error": str(e),
            "metadata": {
                "snippet_report": str(snippet_report),
                "max_vulnerabilities": max_vulnerabilities,
                "show_summary": show_summary,
                "show_progress": show_progress
            }
        }


def fix_vulnerabilities(
    snippet_report: str,
    output_file: str = "vulnerability_fixes.json",
    model: str = "gpt-4o-mini",
    template: str = "vulnerability_fix",
    max_vulnerabilities: Optional[int] = None,
    show_summary: bool = True
) -> List[Dict[str, Any]]:
    """
    Fix vulnerabilities using LLM.
    
    Args:
        snippet_report: Path to vulnerability snippets JSON
        output_file: Output file for fixes
        model: LLM model to use
        template: Prompt template name
        max_vulnerabilities: Limit number to process (for testing)
        show_summary: Show summary after completion
        
    Returns:
        List of vulnerability fix results
    """
    fixer = VulnerabilityFixer(snippet_report, model, template)
    fixes = fixer.fix_all_vulnerabilities(max_vulnerabilities, show_progress=True)
    
    # Save fixes report
    fixer.save_fixes_report(fixes, output_file)
    
    # Show summary if requested
    if show_summary:
        summary = fixer.generate_summary(fixes)
        logger.info(f"Fixing Summary:")
        logger.info(f"  Total vulnerabilities: {summary['total_vulnerabilities']}")
        logger.info(f"  Successful fixes: {summary['successful_fixes']}")
        logger.info(f"  Failed fixes: {summary['failed_fixes']}")
        logger.info(f"  Success rate: {summary['success_rate']:.1f}%")
        logger.info(f"  Severity distribution: {summary['severity_distribution']}")
    
    return fixes


def main():
    """Example usage of the agent-friendly helper function."""
    # Example usage of the helper function
    dir_path = "/Users/izelikson/python/CryptoSlon/SAST/reports/test_7"
    
    result = run_vulnerability_fixer(
        snippet_report=f"{dir_path}/vulnerability_snippets.json",
        output_file=f"{dir_path}/vulnerability_fixes.json",
        model="gigachat-pro",
        template="vulnerability_fix_v6",
        max_vulnerabilities=10,
        show_summary=False,
        show_progress=False,
        log_level="INFO"
    )
    
    if result["success"]:
        print(f"\n✅ Vulnerability fixing successful!")
        data = result["data"]
        print(f"Total fixes: {data['total_fixes']}")
        print(f"Successful fixes: {data['successful_fixes']}")
        print(f"Failed fixes: {data['failed_fixes']}")
        print(f"Success rate: {data['success_rate']:.1f}%")
        print(f"Model used: {data['model_used']}")
        print(f"Template used: {data['template_used']}")
        print(f"Output file: {data['output_file']}")
        
        # Example: Show sample fixes
        fixes = data['fixes']
        successful_fixes = [f for f in fixes if f.get("llm_response")]
        if successful_fixes:
            print(f"Sample successful fixes:")
            for fix in successful_fixes[:2]:
                vuln_info = fix.get("vulnerability_info", {})
                print(f"  {vuln_info.get('type', 'Unknown')}")
                print(f"    File: {vuln_info.get('file', 'Unknown')} (lines {vuln_info.get('location', 'Unknown')})")
                print(f"    CWE: {vuln_info.get('cwe', 'Unknown')}")
    else:
        print(f"\n❌ Vulnerability fixing failed: {result['error']}")
    
    return result


if __name__ == "__main__":
    # Direct Python usage
    result = main()
